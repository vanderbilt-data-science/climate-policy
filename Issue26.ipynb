{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddff7b24-bf9e-4326-adb3-c7d29d957001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.12/site-packages (1.9.0)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (3.2.1)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.26.0)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.32.2)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from openai) (3.9.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu sentence-transformers openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9cd570-f1f4-4b30-8935-ebaeac1866d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b941a7d2-febf-420c-9136-3488e3e93643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/anaconda3/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/anaconda3/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0musage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: console dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook qtconsole run server\n",
      "troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a6aa2-4e4e-4243-b6f3-875eced109f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - ipywidgets\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ipywidgets-8.1.5           |     pyhd8ed1ab_0         111 KB  conda-forge\n",
      "    jupyterlab_widgets-3.0.13  |     pyhd8ed1ab_0         182 KB  conda-forge\n",
      "    pydeck-0.8.0               |     pyhd8ed1ab_0         3.9 MB  conda-forge\n",
      "    widgetsnbextension-4.0.13  |     pyhd8ed1ab_0         878 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.0 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ipywidgets         pkgs/main/osx-arm64::ipywidgets-7.8.1~ --> conda-forge/noarch::ipywidgets-8.1.5-pyhd8ed1ab_0 \n",
      "  jupyterlab_widgets pkgs/main::jupyterlab_widgets-1.0.0-p~ --> conda-forge::jupyterlab_widgets-3.0.13-pyhd8ed1ab_0 \n",
      "  widgetsnbextension pkgs/main/osx-arm64::widgetsnbextensi~ --> conda-forge/noarch::widgetsnbextension-4.0.13-pyhd8ed1ab_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  pydeck             pkgs/main/osx-arm64::pydeck-0.8.0-py3~ --> conda-forge/noarch::pydeck-0.8.0-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53a39d5b-f47f-4837-a2a4-e1db16fa675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Or another suitable model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "055a4fac-dd86-49a4-943d-ad0dd5d933d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faiss_index(docs):\n",
    "    # Encode documents to embeddings and move them to the CPU\n",
    "    embeddings = model.encode(docs, convert_to_tensor=True).cpu().detach().numpy()\n",
    "    \n",
    "    # Initialize FAISS index\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance metric\n",
    "    index.add(embeddings)\n",
    "    return index, embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "766ef013-461b-44a8-88f8-39991b5d6e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example document chunks for each city\n",
    "city_data = {\n",
    "    \"Jacksonville\": [\"Document chunk 1 for Jacksonville\", \"Document chunk 2 for Jacksonville\"],\n",
    "    \"Miami\": [\"Document chunk 1 for Miami\", \"Document chunk 2 for Miami\"],\n",
    "    # Add other cities here\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store indexes and embeddings for each city\n",
    "city_indexes = {}\n",
    "city_embeddings = {}\n",
    "\n",
    "# Loop through city_data and create FAISS indexes for each city\n",
    "for city, docs in city_data.items():\n",
    "    index, embeddings = create_faiss_index(docs)\n",
    "    city_indexes[city] = index\n",
    "    city_embeddings[city] = embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "206adabe-7088-4965-802a-46a2809fd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_all_cities(query, city_indexes, top_k=3):\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True).cpu().detach().numpy()\n",
    "    results = {}\n",
    "\n",
    "    for city, index in city_indexes.items():\n",
    "        _, top_indices = index.search(query_embedding, top_k)\n",
    "        top_docs = [city_data[city][idx] for idx in top_indices[0]]\n",
    "        results[city] = top_docs\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e6fcc14-04e7-4350-a8db-2d9bd4db62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm_combined_results(query, city_indexes):\n",
    "    retrieved_docs = retrieve_from_all_cities(query, city_indexes)\n",
    "    \n",
    "    # Combine document chunks from all cities\n",
    "    combined_docs = \"\\n\\n\".join([f\"{city}:\\n\" + \"\\n\".join(docs) for city, docs in retrieved_docs.items()])\n",
    "\n",
    "    # Create the prompt for the LLM\n",
    "    prompt = f\"Answer the question based on the following city-specific climate action plans:\\n\\n{combined_docs}\\n\\nQuestion: {query}\"\n",
    "    \n",
    "    # Query the LLM (OpenAI in this case)\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",  # Use the appropriate model\n",
    "        prompt=prompt,\n",
    "        max_tokens=300,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d99d9c22-9446-4864-b94b-2499c3ac4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: In Jacksonville's climate action plan, there is a focus on coastal flooding mitigation through measures such as enhancing green infrastructure, implementing stormwater management systems, and promoting coastal resiliency strategies. Specifically, the plan outlines the importance of protecting coastal areas from flooding and sea-level rise by incorporating nature-based solutions and sustainable infrastructure to reduce vulnerability.\n",
      "\n",
      "Miami's climate action plan also addresses coastal flooding by prioritizing adaptation strategies to protect against the impacts of rising sea levels and extreme weather events. The plan emphasizes the need for improving coastal infrastructure, implementing flood management programs, and enhancing coastal resiliency measures to safeguard communities from the risks associated with coastal flooding. Additionally, Miami's plan highlights the importance of collaboration with stakeholders and leveraging innovative technologies to address the challenges posed by coastal flooding in the city.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"sk-proj-gxZhQ2sAl0TmsQzDA2qOT3BlbkFJA0AZTS59Eo0GiScnuJoc\"\n",
    "\n",
    "query = \"How are cities addressing coastal flooding in their climate action plans?\"\n",
    "\n",
    "def query_llm_combined_results(query, city_indexes):\n",
    "    retrieved_docs = retrieve_from_all_cities(query, city_indexes)\n",
    "    \n",
    "    # Combine document chunks from all cities\n",
    "    combined_docs = \"\\n\\n\".join([f\"{city}:\\n\" + \"\\n\".join(docs) for city, docs in retrieved_docs.items()])\n",
    "\n",
    "    # Create the LLM prompt\n",
    "    prompt = f\"Answer the question based on the following city-specific climate action plans:\\n\\n{combined_docs}\\n\\nQuestion: {query}\"\n",
    "    \n",
    "    # Query the LLM with gpt-3.5-turbo\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that helps synthesize city climate action plans.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "response = query_llm_combined_results(query, city_indexes)\n",
    "print(\"LLM Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40ef7b-f0be-44fd-8d85-47d261df23bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
